{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging out Outliers and without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as panda\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "from matplotlib.pyplot import plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import Ridge,BayesianRidge,ElasticNet, Lasso\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = [\n",
    "    LinearRegression(),\n",
    "    RANSACRegressor(),\n",
    "    DecisionTreeRegressor(random_state = 1, criterion = 'mse'),\n",
    "    RandomForestRegressor(random_state = 1, criterion = 'mse'),\n",
    "    SGDRegressor(),\n",
    "#     SVR( kernel = 'rbf'),\n",
    "#     KernelRidge(),\n",
    "    Ridge(solver='auto'),\n",
    "    BayesianRidge(),\n",
    "    ElasticNet(),\n",
    "    Lasso(),\n",
    "#     GradientBoostingRegressor(loss='huber')\n",
    "]\n",
    "\n",
    "\n",
    "classifier_names = [\n",
    "            'linear_regression',\n",
    "            'ransac_regression',\n",
    "            'decisiontree_regression',\n",
    "            'randomforest_regression',\n",
    "            'gradient_descent_regression',\n",
    "#             'svr',  \n",
    "#             'kernel_ridge',\n",
    "            'ridge',\n",
    "            'bayesian_ridge',\n",
    "            'elastic_net',\n",
    "            'lasso',\n",
    "#             'gbr',\n",
    "    \n",
    "]\n",
    "\n",
    "classifier_param_grid = [\n",
    "            \n",
    "            {},\n",
    "            {'ransac_regression__min_samples':[50, 75, 125, 200], 'ransac_regression__max_trials':[50, 125, 200], 'ransac_regression__residual_threshold':[5, 10, 14]},\n",
    "            {'decisiontree_regression__max_depth':[6,7,8,9,10,11]},\n",
    "            {'randomforest_regression__n_estimators':[1,2,3,5,6]} ,\n",
    "            {'gradient_descent_regression__max_iter' : [100, 200, 300]},\n",
    "#             {'svr__C':[1, 5,10]},\n",
    "#             {'kernel_ridge__alpha':[0.01,0.04,1]},\n",
    "            {'ridge__alpha':[0.01,0.04,1]},\n",
    "            {'bayesian_ridge__n_iter':[200,500,600]},\n",
    "            {'elastic_net__alpha' : [0.01,0.04,1,1.2], 'elastic_net__l1_ratio' :[0.2,0.4,0.5]},\n",
    "            {'lasso__alpha' : [0.2,0.4,0.6,1],'lasso__max_iter':[200,400,600]},\n",
    "#             {'gbr__n_estimators' :[1000,2000],'gbr__max_depth':[12,16,8]}\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    "\n",
    "def root_mean_square_error(y, y_predicted):\n",
    "    \n",
    "    return sqrt(mean_squared_error(y,y_predicted))\n",
    "    \n",
    "scorer = make_scorer(root_mean_square_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'all/train_new_details_added.csv'\n",
    "test_data_path = 'all/test_new_details_added.csv'\n",
    "\n",
    "train_data = panda.read_csv(train_data_path)\n",
    "test_data = panda.read_csv(test_data_path)\n",
    "# train_data['max_cat_1'] = train_data.max_cat_1.apply(lambda x: 1 if x=='N' else 0)\n",
    "\n",
    "train_data  = train_data[[i for i in train_data.columns.tolist() if i !='Unnamed: 0']]\n",
    "\n",
    "without_outliers = train_data[train_data['target'] > -29]\n",
    "\n",
    "outliers = train_data[train_data['target'] < -29]\n",
    "\n",
    "round1_x = without_outliers[[i for i in without_outliers.columns.tolist() if i not in ['target','card_id']]]\n",
    "\n",
    "round1_y = without_outliers[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CodeTimer:\n",
    "    \n",
    "    \"\"\"\n",
    "        Utility custom contextual class for calculating the time \n",
    "        taken for a certain code block to execute\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, name=None):\n",
    "        self.name = \" '\"  + name + \"'\" if name else ''\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.clock()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.took = (time.clock() - self.start) * 1000.0\n",
    "        time_taken = datetime.timedelta(milliseconds = self.took)\n",
    "        print('Code block' + self.name + ' took(HH:MM:SS): ' + str(time_taken))\n",
    "\n",
    "\n",
    "\n",
    "def runGridSearchAndPredict(pipeline, x_train, y_train, x_test, y_test, param_grid, n_jobs = 1, cv = 10, score = 'neg_mean_squared_error'):\n",
    "    \n",
    "    response = {}\n",
    "    training_timer       = CodeTimer('training')\n",
    "    testing_timer        = CodeTimer('testing')\n",
    "\n",
    "    with training_timer:\n",
    "\n",
    "        gridsearch = GridSearchCV(estimator = pipeline, param_grid = param_grid, cv = cv, n_jobs = n_jobs, scoring = score)\n",
    "\n",
    "        search = gridsearch.fit(x_train,y_train)\n",
    "\n",
    "        print(\"Grid Search Best parameters \", search.best_params_)\n",
    "        print(\"Grid Search Best score \", search.best_score_)\n",
    "            \n",
    "    with testing_timer:\n",
    "        y_prediction = gridsearch.predict(x_test)\n",
    "            \n",
    "    print(\"Mean squared error score %s\" %mean_squared_error(y_test,y_prediction))\n",
    "    \n",
    "    response['testing_time'] = testing_timer.took\n",
    "    response['_y_prediction'] = y_prediction\n",
    "    response['training_time'] = training_timer.took    \n",
    "    response['mean_squared_error'] = mean_squared_error(y_test,y_prediction)\n",
    "    response['root_mean_squared_error'] = search.best_score_\n",
    "    response['r2_score'] = r2_score(y_test,y_prediction)\n",
    "    response['best_estimator'] = search.best_estimator_\n",
    "    \n",
    "    return response\n",
    "    \n",
    "\n",
    "\n",
    "def analyzeRegressionModelWithOutliers(X,y, outliers):\n",
    "\n",
    "    \n",
    "    _x_train, _x_test, _y_train, _y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "    \n",
    "    \n",
    "    ## simply ignoring the outliers\n",
    "    outlier_x = outliers[[i for i in outliers.columns.tolist() if i not in ['target','card_id']]]\n",
    "    outlier_y =  outliers[['target']]\n",
    "    \n",
    "    outlier_x_train, outlier_x_test, outlier_y_train, outlier_y_test = train_test_split(outlier_x, outlier_y, test_size = 0.2, random_state = 2)\n",
    "    \n",
    "    _x_train = panda.concat([_x_train, outlier_x_train])\n",
    "    \n",
    "    _y_train = panda.concat([_y_train, outlier_y_train])\n",
    "    \n",
    "    _x_test = panda.concat([_x_test, outlier_x_test])\n",
    "    \n",
    "    _y_test = panda.concat([_y_test, outlier_y_test])\n",
    "    \n",
    "    model_metrics = {}\n",
    "\n",
    "    for model, model_name, model_param_grid in zip(classifiers, classifier_names, classifier_param_grid):\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    (model_name, model)\n",
    "            ])\n",
    "\n",
    "            cross_validator = KFold(n_splits = 10, random_state = 12)    \n",
    "            result = runGridSearchAndPredict(pipeline, _x_train, _y_train, _x_test, _y_test, model_param_grid, cv =cross_validator,score = scorer)\n",
    "#             result = runGridSearchAndPredict(pipeline, _x_train, _y_train, _x_test, _y_test, model_param_grid,score = scorer)\n",
    "\n",
    "            _y_prediction = result['_y_prediction']\n",
    "\n",
    "            model_metrics[model_name] = {}\n",
    "            model_metrics[model_name]['training_time'] = result['training_time']\n",
    "            model_metrics[model_name]['testing_time'] = result['testing_time']\n",
    "            model_metrics[model_name]['r2_score'] = result['r2_score']\n",
    "            model_metrics[model_name]['mean_squared_error'] = result['mean_squared_error']\n",
    "            model_metrics[model_name]['root_mean_squared_error'] = result['root_mean_squared_error']\n",
    "            model_metrics[model_name]['best_estimator'] = result['best_estimator']\n",
    "            \n",
    "    return model_metrics\n",
    "    print('Model metrics are \\n :', model_metrics)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def analyzeRegressionModelRemovingOutliers(X,y):\n",
    "\n",
    "    \n",
    "    _x_train, _x_test, _y_train, _y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "    \n",
    "    \n",
    "#     ## simply ignoring the outliers\n",
    "#     outlier_x = outliers[[i for i in outliers.columns.tolist() if i not in ['target','card_id']]]\n",
    "#     outlier_y =  outliers[['target']]\n",
    "    \n",
    "#     outlier_x_train, outlier_x_test, outlier_y_train, outlier_y_test = train_test_split(outlier_x, outlier_y, test_size = 0.2, random_state = 2)\n",
    "    \n",
    "#     _x_train = panda.concat([_x_train, outlier_x_train])\n",
    "    \n",
    "#     _y_train = panda.concat([_y_train, outlier_y_train])\n",
    "    \n",
    "#     _x_test = panda.concat([_x_test, outlier_x_test])\n",
    "    \n",
    "#     _y_test = panda.concat([_y_test, outlier_y_test])\n",
    "    \n",
    "    model_metrics = {}\n",
    "\n",
    "    for model, model_name, model_param_grid in zip(classifiers, classifier_names, classifier_param_grid):\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    (model_name, model)\n",
    "            ])\n",
    "\n",
    "            cross_validator = KFold(n_splits = 10, random_state = 12)    \n",
    "            result = runGridSearchAndPredict(pipeline, _x_train, _y_train, _x_test, _y_test, model_param_grid, cv =cross_validator,score = scorer)\n",
    "#             result = runGridSearchAndPredict(pipeline, _x_train, _y_train, _x_test, _y_test, model_param_grid,score = scorer)\n",
    "\n",
    "            _y_prediction = result['_y_prediction']\n",
    "\n",
    "            model_metrics[model_name] = {}\n",
    "            model_metrics[model_name]['training_time'] = result['training_time']\n",
    "            model_metrics[model_name]['testing_time'] = result['testing_time']\n",
    "            model_metrics[model_name]['r2_score'] = result['r2_score']\n",
    "            model_metrics[model_name]['mean_squared_error'] = result['mean_squared_error']\n",
    "            model_metrics[model_name]['root_mean_squared_error'] = result['root_mean_squared_error']\n",
    "            model_metrics[model_name]['best_estimator'] = result['best_estimator']\n",
    "            \n",
    "    return model_metrics\n",
    "    print('Model metrics are \\n :', model_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outliers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a5b78d7dc53b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzeRegressionModelWithOutliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround1_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround1_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutliers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'outliers' is not defined"
     ]
    }
   ],
   "source": [
    "model_metrics = analyzeRegressionModelWithOutliers(round1_x, round1_y, outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
